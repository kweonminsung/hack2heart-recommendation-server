import numpy as np
from scipy.sparse import coo_matrix
from lightfm import LightFM
from lightfm.data import Dataset
import pickle
import os
import logging

class UserRecommendationModel:
    def __init__(self):
        self.dataset = None
        self.model = None
        self.interaction_matrix = None
        self.user_features = None
        self.is_trained = False

    def prepare_data(self, users, user_metadata, interactions):
        """ë°ì´í„°ì…‹ì„ ì¤€ë¹„í•˜ê³  í–‰ë ¬ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        print("=== ë°ì´í„°ì…‹ ì¤€ë¹„ ì¤‘ ===")
        
        self.dataset = Dataset()
        self.dataset.fit(users, users)  # user â†’ other user ì¶”ì²œ

        all_features = set()
        for feats in user_metadata.values():
            all_features.update(feats)
        self.dataset.fit_partial(user_features=all_features)

        self.interaction_matrix, _ = self.dataset.build_interactions(interactions)
        user_feature_tuples = [(user, feats) for user, feats in user_metadata.items()]
        self.user_features = self.dataset.build_user_features(user_feature_tuples)

        print(f"ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ - ì‚¬ìš©ì: {len(users)}, í”¼ì²˜ ìˆ˜: {len(all_features)}")

    def train_model(self, epochs=10, loss='bpr', num_threads=1):
        """ëª¨ë¸ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤."""
        if self.dataset is None:
            raise ValueError("ë°ì´í„°ì…‹ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. prepare_data()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
        
        print(f"=== ëª¨ë¸ í•™ìŠµ ì‹œì‘ - epochs: {epochs}, loss: {loss} ===")

        self.model = LightFM(loss=loss)
        self.model.fit(
            self.interaction_matrix,
            user_features=self.user_features,
            item_features=self.user_features,
            epochs=epochs,
            num_threads=num_threads
        )
        self.is_trained = True
        print("ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")

    def get_recommendations(self, user_id, top_n=10):
        """íŠ¹ì • ì‚¬ìš©ìì—ê²Œ ì¶”ì²œí•  ì‚¬ìš©ìë“¤ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if not self.is_trained:
            raise ValueError("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. train_model()ì„ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")

        print(f"=== ì‚¬ìš©ì {user_id} ì¶”ì²œ ê³„ì‚° ì¤‘ ===")

        try:
            user_idx = self.dataset.mapping()[0][user_id]
        except KeyError:
            raise ValueError(f"ì‚¬ìš©ì '{user_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        user_ids = list(self.dataset.mapping()[0].keys())
        scores = self.model.predict(
            user_idx,
            np.arange(len(user_ids)),
            user_features=self.user_features,
            item_features=self.user_features
        )

        # ì´ë¯¸ ì•Œê³  ìˆëŠ” ì‚¬ìš©ì ì œì™¸
        known_positives = self.interaction_matrix.tocsr()[user_idx].indices
        # ì¶”ì²œ ì ìˆ˜ ì •ë ¬
        top_items = np.argsort(-scores)

        recommendations = []

        for i in top_items:
            if i == user_idx or i in known_positives:
                continue

            other_user = user_ids[i]
            score = float(scores[i])
            recommendations.append({
                'user_id': other_user,
                'score': score
            })

            if len(recommendations) >= top_n:
                break

        return recommendations

    def save_model(self, filepath):
        """ëª¨ë¸ì„ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
        if not self.is_trained:
            raise ValueError("í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")

        model_data = {
            'model': self.model,
            'dataset': self.dataset,
            'interaction_matrix': self.interaction_matrix,
            'user_features': self.user_features
        }

        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        with open(filepath, 'wb') as f:
            pickle.dump(model_data, f)
        print(f"ëª¨ë¸ì´ {filepath}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def load_model(self, filepath):
        """íŒŒì¼ì—ì„œ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        if not os.path.exists(filepath):
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filepath}")

        with open(filepath, 'rb') as f:
            model_data = pickle.load(f)

        self.model = model_data['model']
        self.dataset = model_data['dataset']
        self.interaction_matrix = model_data['interaction_matrix']
        self.user_features = model_data['user_features']
        self.is_trained = True

        print(f"ëª¨ë¸ì´ {filepath}ì—ì„œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    from dotenv import load_dotenv
    from fetch_data import create_data
    
    load_dotenv()

    print("=== ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘ ===")
    
    model = UserRecommendationModel()
    model_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "model.pkl")
    
    # ëª¨ë¸ì´ ìˆìœ¼ë©´ ë¡œë“œ, ì—†ìœ¼ë©´ ìƒì„±
    if os.path.exists(model_path):
        print("ê¸°ì¡´ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤...")
        model.load_model(model_path)
        users = list(model.dataset.mapping()[0].keys())
    else:
        print("ìƒˆ ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤...")
        users, user_metadata, interactions = create_data()
        model.prepare_data(users, user_metadata, interactions)
        model.train_model(epochs=10)
        model.save_model(model_path)

    user_id = users[0]

    recommendations = model.get_recommendations(user_id, top_n=10)

    print(f"\nğŸ” ì‚¬ìš©ì {user_id}({user_metadata.get(user_id, [])})ì—ê²Œ ì¶”ì²œ:")
    for rec in recommendations:
        print(f"  ğŸ‘‰ ì¶”ì²œ ëŒ€ìƒ: {rec_user_id} (ì˜ˆì¸¡ ì ìˆ˜: {rec['score']:.8f}, ìœ ì € ì •ë³´: {user_metadata.get(rec['user_id'], [])}")

    print("=== ìŠ¤í¬ë¦½íŠ¸ ì¢…ë£Œ ===")
